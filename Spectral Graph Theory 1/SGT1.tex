% --------------------------------------------------------------
% This is all preamble stuff that you don't have to worry about.
% Head down to where it says ``Start here"
% --------------------------------------------------------------
 
\documentclass[12pt]{article}
 

 
\usepackage[margin=1in]{geometry} 
\usepackage{amsmath,amsthm,amssymb}
\usepackage{graphicx}
\usepackage{tabto}

% \newtheorem{problem}{Problem}
% \newtheorem{solution}{Solution}
 
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}

\newenvironment{solution}[2][Solution]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
 
\newenvironment{problem}[2][Problem]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
 
\newenvironment{theorem}[2][Theorem]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{claim}[2][Claim]{\begin{trivlist}
		\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{lemma}[2][Lemma]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{exercise}[2][Exercise]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{reflection}[2][Reflection]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{proposition}[2][Proposition]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{corollary}[2][Corollary]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{definition}[2][Definition]{\begin{trivlist}
		\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}


\newenvironment{example}[2][Example]{\begin{trivlist}
		\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
	
\newenvironment{algorithm}[2][Algorithm]{\begin{trivlist}
		\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
 
\begin{document}
 
% --------------------------------------------------------------
%                         Start here
% --------------------------------------------------------------
 
%\renewcommand{\qedsymbol}{\filledbox}
 
\title{Spectral Graph Theory}
\author{Zhiwei Zhang}

 
\maketitle
\section{Introduction}
\subsection{Adjacency Matrix Representation of A Graph}
We represent a Graph $G$ with a square adjacency matrix $A$, where entry $$a_{ij} = \begin{cases}
1 &\text{if (i, j) is an edge in }G \\
0 &\text{otherwise}
\end{cases}$$
Evidently, the matrix is symmetric, or $a_{ij} = a_{ji}$. Therefore by spectral theorem, we have a orthonormal basis of eigenvectors, with real eigenvalues associated.

\section{Counting Paths with Adjacency Matrix}
\begin{theorem}
	Let $G$ be a graph on labeled vertices, let $A$ be its adjacency
	matrix, and let $k$ be a positive integer. Then $A_{i,j}^{k}$ is equal to the number of
	walks from $i$ to $j$ that are of length $k$ .
\end{theorem} 

\begin{proof}
	The proof is fairly simple, and we will do it by induction.\\
	\newline
	When $k = 1$, we look at the original adjacency matrix, and $A_{i, j}$ indicates whether there's an edge between $i, j$, which is a path of length 1.\\
	\newline
	Now assume that the statement is true for $k$, and
	prove it for $k + 1$. \\
	\newline
	\textbf{Let's first think about it intuitively, $A^{k}$ gives the number of paths walks from $i$ to all other points. 
		If one such point is $v$, then we just need to determine if there's and edge from $v$ to $j$, 
		if so then we just add the number of walks from $i$ to  $k$.}\\
	\newline
	Let $z$ be any vertex of $G$. If there are $b_{i,z}$ walks of length $k$ from $i$ to $z$, and there are $a_{z,j}$ walks of length one (in other words, edges)
	from $z$ to $j$, then there are $b_{i,z}a_{z,j}$ walks of length $k + 1$ from $i$ to $j$ whose
	next-to-last vertex is $z$. Therefore, the number of all walks of length $k + 1$ from $i$ to $j$ is:
	$$
	c(i,j) = \sum_{z \in G} b_{i,z}a_{z,j}
	$$
	Since $b_{i, z}$ correspond to an entry in $A^k$, the formula above is basically a matrix multiplication. 
\end{proof}

At this point, it's a good habit to check our proof again. Ask ourselves this question:
\begin{center}
	\textit{We know $A^{k}_{i, j}$ represents some number of walks from $i$ to $j$, but does it count all of them?}
\end{center}
We'll leave it as a quick thought exercise.
\subsection{Connectivity}
\begin{theorem}
	Let $G$ be a simple graph on $n$ vertices, and let $A$ be the
	adjacency matrix of $G .$ Then $G$ is connected iff $( I + A ) ^ { n - 1 }$
	consists of strictly positive entries.
\end{theorem}
\begin{proof}
	We will only give the central idea of the proof here\\
	\newline
	A path from one point to another consists at most $n$ vertices, or $n-1$ edges. Therefore, if we cannot find a path between two points within $n-1$ edges, the graph is not connected\\
	\newline
	Using the previous theorem, we know that $A_{n-1}$ gives the number of paths if length $n-1$ between any two points, however, this is \textbf{not enough}.\\
	\newline
	Notice that the theorem indicates it's $(I + A)^{n-1}$ instead of $A^{n-1}$. So what does the $I$ do?\\
	\newline
	Graphically, it means that we assume any vertex is connected to itself. What is $(I + A)^{n-1}$ then? \\
	\newline
	For simplicity, call $(I + A) = A'$. With $A'_{i, i} = 1$, $A'^{k}$ no longer counts the number of paths of length \textbf{strictly} $k$, but the number of paths of length $\leq k$. This is because we don't have to move to another point every time we multiply $A'$, we can choose to stay at the same point since $A'_{i, i} = 1$.\\
	\newline
	Therefore $(I + A)^{n-1}$ counts the number of paths of length $\leq n - 1$, and if there still exist an 0 entry $A'^{n-1}_{i, j}$, then it means if we cannot find a path between two points within $n-1$ edges, the graph is not connected.
\end{proof}

\textbf{Some Remarks}: Bellman-Ford algorithm also uses the property that a path between two vertices in a connected graph has edge count at most $n-1$ to check for negative cycles.


\section{Matrix Tree Theorem (Many Versions)}
It turns out that we can use matrix to count the number of spanning trees with matrices. There are many matrix tree theorems, and we here will just talk about a few of them.\\

\subsection{Incidency Matrix}We first define the incidency matrix $A$ for a graph $G$\\
\newline
The incidency matrix of $G(V, E)$ is a  $n \times m$ matrix, where $n = |V|, m = |E|$. We label the edges $e_1, \cdots, e_m$ and vertices $v_1, \cdots, v_n$. Then
$$A_{i, k} = \begin{cases}
1 \text{ if }i \text{ is the head of the edge of } e_k\\
-1 \text{ if }i \text{ is the tail of the edge of } e_k\\
0 \text{ otherwise}
\end{cases}$$

\begin{theorem}
	Let $G$ be a directed graph without loops, and let $A$ be
	the incidency matrix of $G .$ Remove any row from $A ,$ and let $A _ { 0 }$ be the
	remaining matrix. Then the number of spanning trees of $G$ is det $A _ { 0 } A _ { 0 } ^ { T }$
\end{theorem}

\begin{proof}
	Let us assume, without loss of generality, that the last row of $A$
	was omitted. Let $B$ be an $( n - 1 ) \times ( n - 1 )$ submatrix of $A _ { 0 } .$ (If $m < n - 1 )$ ,
	then $G$ cannot be connected, and it has no spanning trees.) We claim that
	$| \operatorname { det } B | = 1$ if and only if the subgraph $G ^ { \prime }$ corresponding to the columns of
	$B$ is a spanning tree (including the last row), and det $B = 0$ otherwise.\\
	\newline 
	First we need to notice that $G'$ is basically a subgraph with all the vertices but only $n - 1$ edges.\\
	\newline 
	We induct on $n .$ First, let us assume that there
	is a vertex $v _ { i } ( i \neq n )$ of degree one in $G ^ { \prime } .$ (The degree of a vertex in an
	undirected graph is the number of all edges adjacent to that vertex.) Then
	the $i$ th row of $B$ contains exactly one nonzero element, and that element is 1 or $- 1 .$ Expanding det $B$ by this row, and using the induction hypothesis,
	the claim follows. Indeed, $G ^ { \prime }$ is a spanning tree of $G$ if and only if $G ^ { \prime } - v _ { i }$
	is a spanning tree of $G - v _ { i } .$\\
	\newline
	If $G^{\prime}$ has no vertices of degree one (except possibly $v_{n}$,
	the vertex associated to the deleted last row $) .$ Then $G ^ { \prime }$ is not a spanning tree (cus no leaf). \\
	\newline
	Since $G ^ { \prime }$ has $n - 1$ edges, and is not a spanning tree, there
	must be a vertex in $G ^ { \prime }$ that has degree zero. If this vertex is not $v _ { n } ,$ then $B$
	has a zero row, and det $B = 0 .$ If this vertex is $v _ { n } ,$ then each column of $B$ contains one $1 ,$ and one $- 1$ as each edge has a head and a tail. Therefore,
	the sum of all rows of $B$ is $0 ,$ so the rows of $B$ are linearly dependent, and
	$\operatorname { det } B = 0$\\
	\newline 
	The Binet-Cauchy formula, that can be found in most Linear Algebra
	textbooks, says that
	\[ \operatorname { det } A _ { 0 } A _ { 0 } ^ { T } = \sum ( \operatorname { det } B ) ^ { 2 }\] where the sum ranges over all $( n - 1 ) \times ( n - 1 )$ submatrices $B$ of $A _ { 0 }$ .
	However, we have just seen that $( \operatorname { det } B ) ^ { 2 } = 1$ if and only if $B$ corresponds
	to a spanning tree of $A ,$ and $( \operatorname { det } B ) ^ { 2 } = 0$ otherwise. Therefore, the proof
	follows.
\end{proof}

\begin{theorem}
	Let $U$ be a simple undirected graph. Let $\left\{ v _ { 1 } , v _ { 2 } , \cdots , v _ { n } \right\}$ denote the vertices of $U$. Define the $( n - 1 ) \times ( n - 1 )$ matrix $L _ { 0 }$ by
	\[l_{i, j} = 
	\begin{cases} 
	\text{degree of } v _ { i } & i = j \\
	l _ { i , j } = - 1 & i \neq j \text{ and } (v_{ i },v _ { j }) \in E\\
	0 & \text{otherwise}
	\end{cases}\]
	Then the theorem states det $L_0$ counts the number of spanning trees in $U$
\end{theorem}
\end{document}








